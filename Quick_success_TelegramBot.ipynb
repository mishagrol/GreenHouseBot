{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **<span style='color:#F1A424'>Innavation Workshop - 2023. Quick success</span>**\n",
        "#### **<span style='color:#F1A424'>Practical part of Quick Success - TelegramBot, Skoltech, Moscow-2023</span>**\n",
        "\n",
        "**Instructors:** Anna Petrovskaia, Mikhail Gasanov and Elizveta Kiseleva\n",
        "\n",
        "--------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idWstsurrACC"
      },
      "source": [
        "### 1. Register a Telegram bot\n",
        "\n",
        "Register your bot in Telegram and get a token.\n",
        "\n",
        "1. To register a new bot, launch the BotFather bot and send the command:\n",
        "\n",
        "`/newbot`\n",
        "\n",
        "2. In the name field, specify the name of the bot being created, for example, `Crop Bot`. This name will be seen by users when communicating with the bot.\n",
        "\n",
        "3. In the username field, specify the username of the bot being created, for example `Crop_bot`. By user name, you will be able to find the bot in Telegram. The user name must end in `...Bot` or `..._bot`.\n",
        "\n",
        "4. As a result, you will receive a token. Save it, it will be needed in the future.\n",
        "\n",
        "5. Install the icon for the bot — the `logo.png` file. Send the BotFather bot the command:\n",
        "\n",
        "`/setuserpic`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGykHVjCU3rO"
      },
      "source": [
        "6. Save token to file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Q_ZM4Da4q_2k"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open(\".token_telegram.json\", \"w\") as file:\n",
        "    creds = {\"token\": \"<YOUR UNIQUE TOKEN FROM BOT FATHER>\"}\n",
        "    json.dump(creds, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsKlcWh3VI2-"
      },
      "source": [
        "## 2. Download pretrained model from Drive\n",
        "\n",
        "\n",
        "Example of file URL\n",
        "\n",
        "`https://drive.google.com/file/d/1Fg0ZbTeQryYfCB-m-iTUMGdm0B6Y9_Io/view?usp=drive_link`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La2dP5gZVSC-"
      },
      "outputs": [],
      "source": [
        "# use unique if from gdrive - example: 1Fg0ZbTeQryYfCB-m-iTUMGdm0B6Y9_Io\n",
        "!gdown \"file_id\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMn4gu6YrIhP"
      },
      "source": [
        "## 3. Install packages for telegram bot\n",
        "\n",
        "\n",
        "__aiogram__\n",
        "\n",
        "aiogram is a modern and fully asynchronous framework for Telegram Bot API written in Python 3.8 using asyncio and aiohttp.\n",
        "\n",
        "https://aiogram.dev/\n",
        "\n",
        "\n",
        "__nest-asyncio__\n",
        "\n",
        "By design asyncio does not allow its event loop to be nested. This presents a practical problem: When in an environment where the event loop is already running it’s impossible to run tasks and wait for the result. Trying to do so will give the error “RuntimeError: This event loop is already running”.\n",
        "\n",
        "https://github.com/erdewit/nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfIXMgNdRm_O",
        "outputId": "b76790f2-41a4-4094-e91a-d7461015827a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 196 kB 15.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 65.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 -q install nest_asyncio\n",
        "!pip3 -q install aiogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Add your Network\n",
        "\n",
        "Class for your neural net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "\n",
        "    # Network Initialisation\n",
        "    def __init__(self, params):\n",
        "\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        Cin, Hin, Win = params[\"shape_in\"]\n",
        "        init_f = params[\"initial_filters\"]\n",
        "        num_fc1 = params[\"num_fc1\"]\n",
        "        num_classes = params[\"num_classes\"]\n",
        "        self.dropout_rate = params[\"dropout_rate\"]\n",
        "\n",
        "        # Convolution Layers\n",
        "        self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
        "        h, w = findConv2dOutShape(Hin, Win, self.conv1)\n",
        "        self.conv2 = nn.Conv2d(init_f, 2 * init_f, kernel_size=3)\n",
        "        h, w = findConv2dOutShape(h, w, self.conv2)\n",
        "        self.conv3 = nn.Conv2d(2 * init_f, 4 * init_f, kernel_size=3)\n",
        "        h, w = findConv2dOutShape(h, w, self.conv3)\n",
        "        self.conv4 = nn.Conv2d(4 * init_f, 8 * init_f, kernel_size=3)\n",
        "        h, w = findConv2dOutShape(h, w, self.conv4)\n",
        "\n",
        "        # compute the flatten size\n",
        "        self.num_flatten = h * w * 8 * init_f\n",
        "        self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
        "        self.fc2 = nn.Linear(num_fc1, num_classes)\n",
        "\n",
        "    def forward(self, X):\n",
        "\n",
        "        # Convolution & Pool Layers\n",
        "        X = Functional.relu(self.conv1(X))\n",
        "        X = Functional.max_pool2d(X, 2, 2)\n",
        "        X = Functional.relu(self.conv2(X))\n",
        "        X = Functional.max_pool2d(X, 2, 2)\n",
        "        X = Functional.relu(self.conv3(X))\n",
        "        X = Functional.max_pool2d(X, 2, 2)\n",
        "        X = Functional.relu(self.conv4(X))\n",
        "        X = Functional.max_pool2d(X, 2, 2)\n",
        "\n",
        "        X = X.view(-1, self.num_flatten)\n",
        "\n",
        "        X = Functional.relu(self.fc1(X))\n",
        "        X = Functional.dropout(X, self.dropout_rate)\n",
        "        X = self.fc2(X)\n",
        "        return Functional.log_softmax(X, dim=1)\n",
        "\n",
        "\n",
        "def findConv2dOutShape(hin, win, conv, pool=2):\n",
        "    # get conv arguments\n",
        "    kernel_size = conv.kernel_size\n",
        "    stride = conv.stride\n",
        "    padding = conv.padding\n",
        "    dilation = conv.dilation\n",
        "\n",
        "    hout = np.floor(\n",
        "        (hin + 2 * padding[0] - dilation[0] * (kernel_size[0] - 1) - 1) / stride[0] + 1\n",
        "    )\n",
        "    wout = np.floor(\n",
        "        (win + 2 * padding[1] - dilation[1] * (kernel_size[1] - 1) - 1) / stride[1] + 1\n",
        "    )\n",
        "\n",
        "    if pool:\n",
        "        hout /= pool\n",
        "        wout /= pool\n",
        "    return int(hout), int(wout)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3KBudg2rVzf"
      },
      "source": [
        "## 5. Edit bot.py file and fill missed parts of code\n",
        "\n",
        "* Open file `GreenHouseBot/bot.py`\n",
        "* Edit `run_model()` function\n",
        "* Save file \n",
        "* Run bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-01gcU1S32U",
        "outputId": "3b43b503-faaa-4ab1-f081-c3102372cd3f"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import asyncio\n",
        "from aiogram import Bot, Dispatcher, types\n",
        "from aiogram.filters import CommandStart, Command\n",
        "from aiogram.enums import ParseMode\n",
        "from aiogram import F\n",
        "import uuid\n",
        "import sys\n",
        "import time, json, io\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as Functional\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "credintails = json.load(open(\".token_telegram.json\", \"r\"))\n",
        "\n",
        "TOKEN = credintails[\"token\"]\n",
        "logging.basicConfig(level=logging.INFO, stream=sys.stdout)\n",
        "\n",
        "# Initialize bot and dispatcher\n",
        "dp = Dispatcher()\n",
        "\n",
        "bot = Bot(TOKEN, parse_mode=ParseMode.HTML)\n",
        "\n",
        "\n",
        "def run_model(image: np.array) -> int:\n",
        "\n",
        "    ### BEGIN\n",
        "\n",
        "    ## END YOUR SOLUTION\n",
        "    device = torch.device(str(\"cuda:0\") if torch.cuda.is_available() else \"cpu\")\n",
        "    cnn_model = cnn_model.to(device)\n",
        "    cnn_model.eval()\n",
        "    my_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(), transforms.Resize((46, 46))]\n",
        "    )\n",
        "    image_tensor = my_transforms(image).unsqueeze(0)\n",
        "    image_tensor = image_tensor.to(device)\n",
        "    ### BEGIN YOUR SOLUTION\n",
        "\n",
        "    ### END YOUR SOLUTION\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    pred = pred.cpu().detach().numpy()\n",
        "    del image_tensor, output, cnn_model\n",
        "    torch.cuda.empty_cache()  # Clear cache\n",
        "    return pred[0][0]\n",
        "\n",
        "\n",
        "@dp.message(CommandStart())\n",
        "async def send_welcome(message: types.Message):\n",
        "    \"\"\"\n",
        "    This handler will be called when user sends /start or /help command\n",
        "    \"\"\"\n",
        "    await message.reply(\"Hi!\\n\\nI'm CropBot!\\n\\nI need photos 🥦.\")\n",
        "\n",
        "\n",
        "@dp.message(F.content_type.in_({\"photo\", \"document\"}))\n",
        "async def echo(message: types.Message):\n",
        "    file_in_io = io.BytesIO()\n",
        "    if message.content_type == \"photo\":\n",
        "        await bot.download(message.photo[-1], destination=file_in_io)\n",
        "    elif message.content_type == \"document\":\n",
        "        await bot.download(message.document, destination=file_in_io)\n",
        "    plant_image = np.array(Image.open(io.BytesIO(file_in_io.read())))\n",
        "    await bot.send_message(message.from_user.id, \"Neural nets started!\")\n",
        "    task = run_model(image=plant_image)\n",
        "    human_dict = {0: \"Mint\", 1: \"Rausmarine\"}\n",
        "    await message.answer(human_dict[task])\n",
        "\n",
        "\n",
        "# Handle /cancel command\n",
        "@dp.message(Command(\"cancel\"))\n",
        "async def cancel_handler(message: types.Message):\n",
        "    await message.reply(\n",
        "        \"Canceled, enter /start\", reply_markup=types.ReplyKeyboardRemove()\n",
        "    )\n",
        "\n",
        "\n",
        "async def main() -> None:\n",
        "    # And the run events dispatching\n",
        "    await dp.start_polling(bot)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTle4JsBWIIu"
      },
      "source": [
        "## End ☘️\n",
        "-----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nest asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
